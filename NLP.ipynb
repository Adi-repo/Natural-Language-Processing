{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this #earthquake M...\n",
       "1                  Forest fire near La Ronge Sask. Canada\n",
       "2       All residents asked to 'shelter in place' are ...\n",
       "3       13,000 people receive #wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby #Alaska as ...\n",
       "                              ...                        \n",
       "7608    Two giant cranes holding a bridge collapse int...\n",
       "7609    @aria_ahrary @TheTawniest The out of control w...\n",
       "7610    M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
       "7611    Police investigating after an e-bike collided ...\n",
       "7612    The Latest: More Homes Razed by Northern Calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will extract all the unique words from the dataset\n",
    "def unique_words(df):\n",
    "    unique_words = []\n",
    "    for i in range(len(df)):\n",
    "        for word in df['text'][i].split():\n",
    "            if word not in unique_words:\n",
    "                unique_words.append(word)\n",
    "    return unique_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = unique_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will create a dictionary of all the unique words and their frequency in the dataset\n",
    "def word_freq(df):\n",
    "    unique_words = []\n",
    "    for i in range(len(df)):\n",
    "        for word in df['text'][i].split():\n",
    "            if word not in unique_words:\n",
    "                unique_words.append(word)\n",
    "    word_freq = {}\n",
    "    for word in unique_words:\n",
    "        word_freq[word] = 0\n",
    "    for i in range(len(df)):\n",
    "        for word in df['text'][i].split():\n",
    "            word_freq[word] += 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = word_freq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do tokenization of all the words present in the dictionary\n",
    "def tokenize_words(dictionary):\n",
    "    tokens = {}\n",
    "    ind = 0\n",
    "    for word in dictionary:\n",
    "        tokens[word] = ind\n",
    "        ind += 1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_words(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "submission = pd.read_csv('dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text   \n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...  \\\n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary which has id as keys and text as values\n",
    "def create_dict(df):\n",
    "    dict = {}\n",
    "    for i in range(len(df)):\n",
    "        dict[df['id'][i]] = df['text'][i]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = create_dict(train)\n",
    "#print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['id','keyword', 'location'], axis=1, inplace=True)\n",
    "test.drop(['id', 'keyword', 'location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to find number of zeroes and ones in the target column\n",
    "def count_zeroes_ones(target):\n",
    "    zeroes = 0\n",
    "    ones = 0\n",
    "    for i in range(len(target)):\n",
    "        if target[i] == 0:\n",
    "            zeroes += 1\n",
    "        else:\n",
    "            ones += 1\n",
    "    return zeroes, ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes, ones = count_zeroes_ones(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a bar graph to show the distribution of the target column\n",
    "import matplotlib.pyplot as plt\n",
    "# change color of the bars\n",
    "plt.bar(['zeroes', 'ones'], [zeroes, ones], color=['red', 'green'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lablels = train['target'].tolist()\n",
    "tweets = train['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(tweets, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class twitterdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = twitterdataset(inputs, lablels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [01:30<00:00, 4.89MB/s] \n",
      "d:\\Anaconda\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aditya Singh\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  1%|          | 10/1428 [19:58<47:44:32, 121.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7737, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 20/1428 [31:56<21:30:10, 54.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6893, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1428 [2:59:22<59:27:15, 153.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6924, 'learning_rate': 3e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1428 [3:07:41<19:56:05, 51.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6522, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 50/1428 [3:16:33<19:40:40, 51.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6689, 'learning_rate': 5e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 60/1428 [3:55:24<226:51:50, 597.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5798, 'learning_rate': 6e-06, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 70/1428 [4:03:46<25:08:19, 66.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5964, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 80/1428 [4:11:48<17:59:50, 48.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5831, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 90/1428 [5:21:03<143:32:34, 386.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4735, 'learning_rate': 9e-06, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 100/1428 [5:43:44<28:45:16, 77.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5546, 'learning_rate': 1e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 106/1428 [6:58:05<478:44:44, 1303.69s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 21\u001b[0m\n\u001b[0;32m      1\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      2\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./results\u001b[39m\u001b[39m\"\u001b[39m,          \u001b[39m# output directory\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     num_train_epochs\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,              \u001b[39m# total # of training epochs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     logging_steps\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     13\u001b[0m     model\u001b[39m=\u001b[39mmodel,                         \u001b[39m# the instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,                  \u001b[39m# training arguments, defined above\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[39m# optimizers=[optimizer]\u001b[39;00m\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1659\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1661\u001b[0m )\n\u001b[1;32m-> 1662\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1663\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1664\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1665\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1666\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1667\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1927\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1928\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1929\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1931\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1932\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1933\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1934\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1935\u001b[0m ):\n\u001b[0;32m   1936\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\trainer.py:2699\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2698\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2699\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   2701\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   2702\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\trainer.py:2731\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2729\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2730\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2731\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m   2732\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2733\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2734\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1563\u001b[0m     input_ids,\n\u001b[0;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1572\u001b[0m )\n\u001b[0;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1023\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1024\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1025\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1026\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1027\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1028\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1029\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    534\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    535\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 537\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    539\u001b[0m )\n\u001b[0;32m    540\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    542\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 236\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:549\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m--> 549\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[0;32m    550\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:449\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 449\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    450\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # total # of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    # eval_dataset=test_dataset          # evaluation dataset\n",
    "    # compute_metrics=compute_metrics    # define metrics function\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
