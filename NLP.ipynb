{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this #earthquake M...\n",
       "1                  Forest fire near La Ronge Sask. Canada\n",
       "2       All residents asked to 'shelter in place' are ...\n",
       "3       13,000 people receive #wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby #Alaska as ...\n",
       "                              ...                        \n",
       "7608    Two giant cranes holding a bridge collapse int...\n",
       "7609    @aria_ahrary @TheTawniest The out of control w...\n",
       "7610    M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
       "7611    Police investigating after an e-bike collided ...\n",
       "7612    The Latest: More Homes Razed by Northern Calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will extract all the unique words from the dataset\n",
    "def unique_words(df):\n",
    "    unique_words = []\n",
    "    for i in range(len(df)):\n",
    "        for word in df['text'][i].split():\n",
    "            if word not in unique_words:\n",
    "                unique_words.append(word)\n",
    "    return unique_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = unique_words(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will create a dictionary of all the unique words and their frequency in the dataset\n",
    "def word_freq(df):\n",
    "    unique_words = []\n",
    "    for i in range(len(df)):\n",
    "        for word in df['text'][i].split():\n",
    "            if word not in unique_words:\n",
    "                unique_words.append(word)\n",
    "    word_freq = {}\n",
    "    for word in unique_words:\n",
    "        word_freq[word] = 0\n",
    "    for i in range(len(df)):\n",
    "        for word in df['text'][i].split():\n",
    "            word_freq[word] += 1\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = word_freq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do tokenization of all the words present in the dictionary\n",
    "def tokenize_words(dictionary):\n",
    "    tokens = {}\n",
    "    ind = 0\n",
    "    for word in dictionary:\n",
    "        tokens[word] = ind\n",
    "        ind += 1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_words(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
